<?xml version='1.1' encoding='UTF-8'?>
<flow-definition plugin="workflow-job@2.39">
  <actions>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobAction plugin="pipeline-model-definition@1.7.0"/>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction plugin="pipeline-model-definition@1.7.0">
      <jobProperties/>
      <triggers/>
      <parameters/>
      <options/>
    </org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction>
  </actions>
  <description>This pipeline will attempt to pull a tar.gz file that contains the clinical data files and stage them as live data.  If data exists it will reboot hpds after pulling data.</description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <definition class="org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition" plugin="workflow-cps@2.81">
    <script>import groovy.json.JsonSlurper;

/**
 * This pipeline will attempt to pull a tar.gz file that contains the clinical data files and stage them as live data. 
 * If data exists it will reboot hpds after pulling data.
 **/

/* in the pipeline we are expected to be using build spec to control builds and data deployment in the application stack
Should fail if not set running .  Use the s3 data pull directly for troubleshooting and injecting a custom s3 location. */

def missings3Location = true // only set to false if s3 location is specified in build spec
def clinical_data_s3_location = ''
      
pipeline {
   agent any

   stages {
        stage(&apos;Retrieve Build Spec&apos;) { 
            steps {
                script {
                    def result = build job: &apos;Retrieve Build Spec&apos;
                    retrieveBuildSpecId = result.number
                }
                script {
                    copyArtifacts filter: &apos;*&apos;, projectName: &apos;Retrieve Build Spec&apos;, selector: specific(&quot;&quot;+retrieveBuildSpecId)
                    sh &apos;cat build-spec.json&apos;
                    sh &apos;cat pipeline_git_commit.txt&apos;
                    sh &apos;pwd&apos;
                    sh &apos;ls&apos;
                    def path = pwd()
                    def filePath = path + &apos;/build-spec.json&apos;
                    echo filePath
                    def buildSpec = new JsonSlurper().parse(new File(filePath))

                    for(def build : buildSpec.datafiles){
                        if(build.project_name.equalsIgnoreCase(&quot;phenotype data&quot;)) {
                           missings3Location = false
                           clinical_data_s3_location = build.clinical_data_s3_location
                           echo clinical_data_s3_location
                        }
                    }
                    
                }
            }
        }
        // fail build if build spec does not have s3 location
        stage(&apos;Pull s3 data&apos;) {
            steps{
                script {
                    if(missings3Location) {
                        error &apos;# !!!Missing s3 location for clinical data tar!!! #&apos;
                        currentBuild.result = &apos;FAILURE&apos;
                        return;
                    }
                }
                script {
                    def result = build job: &apos;Clinical data pull from s3&apos;, parameters: [[$class: &apos;StringParameterValue&apos;, name: &apos;clinical_data_s3_location&apos;, value: clinical_data_s3_location]]
                }
                script {
                    def result = build job: &apos;Restart HPDS&apos;, parameters: []
                } 
            }
        }
    }
}
</script>
    <sandbox>false</sandbox>
  </definition>
  <triggers/>
  <disabled>false</disabled>
</flow-definition>
